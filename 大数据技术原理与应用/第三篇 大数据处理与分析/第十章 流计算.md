# 第十章 流计算
## 10.1 流计算概述
### 10.1.1 静态数据和流数据
1. 静态数据：数据仓库，利用ETL加载进入，利用数据挖掘和OLAP（On-Line Analytical Processing）分析
![](https://i.postimg.cc/G3757WrG/11-1.png)
2. 流数据：数据以大量、快速、时变的流形式持续到达，如PM2.5的检测，电商点击流等
- 数据快速持续到达，潜在大小无穷无尽
- 数据来源众多，格式复杂
- 数据量大，但是不关注存储，一旦处理，要么丢弃要么存储
- 注重数据的整体价值，不过分关注个别数据
- 数据顺序颠倒，或者不完整，系统无法控制将要处理的新到达的数据元素的顺序

### 10.1.2 批量计算和实时计算
- 批量计算：充裕时间处理静态数据，如Hadoop
- 流数据不适合批量计算，因为流数据不适合传统关系模型
- 流数据采用实时计算，响应时间为秒级

### 10.1.3 流计算概念
流计算：实时获取来自不同数据源的海量数据，经过实时分析处理，获得有价值的信息，数据的价值随时间的流逝而降低，由此需要一个低延迟、可扩展、高可靠的处理引擎

需求：
- 高性能
- 海量式
- 实时性
- 分布式
- 易用性
- 可靠性

### 10.1.4 流计算与Hadoop
能不能将数据切成小的片段，每隔一个周期就启动呢？不行
- 切片可以降低延迟，但是增加开销
- 处理片段的依赖关系
- 需要改造MapReduce，伸缩性不强

### 10.1.5 流计算框架
商业级：IBM InfoSphere Streams和IBM StreamBase
开源类：Twitter Sotrm（阿里巴巴的JStorm是基于此）、Yahoo！S4
公司自用：Facebook Puma、Dstream（百度）、银河流数据处理（淘宝）

## 10.2 流计算的处理流程
### 10.2.1 概述
传统的数据处理流程，需要先采集数据并存储在关系数据库等数据管理系统中，再由客户通过查询进行交互
![](https://i.postimg.cc/c4q0ktdQ/11-4.png)
这样隐含2个前提：
- 存储的数据是旧的，查询时不具备时效性
- 需要用户主动发出查询

流计算包含3个阶段：数据实时采集、数据实时计算、实时查询服务
![](https://i.postimg.cc/SNWqBQKH/11-5.png)

### 10.2.2 数据实时采集
- 数据实时采集阶段通常采集多个数据源的海量数据，需要保证实时性、低延迟与稳定可靠
- 以日志数据为例，数据分散存储在不同的机器上，因此需要实时汇总来自不同机器上的日志数据
- Facebook的Scribe，LinkedIn的Kafka，淘宝的Time Tunnel，基于Hadoop的Flume

![](https://i.postimg.cc/vHRx7mjK/11-6.png)
1. Agent：主动采集数据，并把数据推送到Collector
2. Collector：接受数据，并实现有序、可靠、高性能的转发
3. Store：存储Collector转发的数据

一般来说，流计算不存储Store部分

### 10.2.3 数据实时计算
- 对采集数据进行实时的分析和计算，并反馈结果
- 经过流处理的数据，可以存储或丢弃

### 10.2.4 实时查询服务
- 经由流计算框架得出的结果可供用户进行实时查询、展示或存储
- 实时查询可以不断更新结果，并将用户所需实时推送

与传统的差异：
- 处理数据：实时和静态
- 获取查询：实时和过去
- 信息推送：主动和被动

## 10.3 流计算的应用
流计算适合于处理持续到达的流数据，对数据处理有较高实时性要求的场景，如淘宝的用户实时浏览轨迹，进行个性化推荐，双11的广告效果分析，实时交通的数据处理等

## 10.4 开源流计算框架Storm
### 10.4.1 Storm简介
Twitter Storm是开源分布式实时计算系统，如同Hadoop对批处理一般，Storm简单高效可靠地处理流数据，并支持多种语言。
![](https://i.postimg.cc/rw7pTZkP/11-9.png)

### 10.4.2 Storm的特点
- 整合性：和数据库系统、消息队列整合
- 简单API
- 可扩展性：分布式集群
- 容错性
- 可靠性

### 10.4.3 Storm的设计思想
Storm属于包括：Streams、Spouts、Bolts、Topology和Stream Groupings

1. Streams：Storm将数据流Stream描述成无限的Tuple序列，这些Tuple序列会以分布式的方式并行的创建和处理  
![](https://i.postimg.cc/0yk4Q986/11-10.png)  
每个tuple是一堆值，每个值有一个名字，类型不限。本来应该是key-value的Map，但是由于名字已经事先定义好，所以只需按序填入value，所以形式上是Value List
2.  Spout：Stream的源头的抽象，持续发出Tuple 。Spout是个主动角色，在接口内部有个nextTuple函数，Storm不停调用 
![](https://i.postimg.cc/d0dGcTzG/11-11.png)
3.  Bolt：Stream将状态转换过程抽象为Bolt，即可处理Tuple，也可以将处理后的Tuple作为新的Streams发送给其他Bolt，可以执行过滤，函数操作，Join，操作数据库等操作。Bolt是个被动角色，有一个execute(Tuple input)方法，接收到消息后会调用。  
![](https://i.postimg.cc/GpkT5nyQ/11-12.png)
4.  Topology：Storm将Spouts和Bolts组成的网络抽象成Topology，它被提交到Storm集群执行，可当成流程转换图。Topology里面的Spout或Bolt都包含处理逻辑，连接表示数据流动方向，且这些组件是并行运行的。在Topology的具体实现上，Storm中仅仅是Thrift结构体，支持各种语言定义  
![](https://i.postimg.cc/mrRghzPY/11-13.png)
5.  Stream Grouping：用于告知Topology如何在两个组件间（Spout和Bolt或不同Bolt）传递Tuple。一个任务在何时，如何发送Tuple都有其定义。  
![](https://i.postimg.cc/nr6HxC8Q/11-14.png)
- ShuffleGrouping：随机分组，随机分发Stream的Tuple，保证每个Bolt接受Tuple数量大体一致
- FieldsGrouping：按字段分组，保证相同字段的Tuple分配到同一个Task
- AllGrouping：广播发送，每一个Task都会收到所有Tuple
- GlobalGrouping：全局分组，所有Tuple发送到同一个Task
- NonGrouping：不分组，当前Task的执行会和它的被订阅者在同一个线程中执行
- DirectGrouping：直接分组，直接指定

### 10.4.4 Storm框架设计
![](https://i.postimg.cc/SsRqzWkM/11-15-1.png)

Storm集群采用“Master-Worker”的节点方式：
- Master节点运行“Nimbus”的后台程序，负责分发代码、为Worker分配任务和检测故障
- Worker节点运行“Supervisor”的后台程序，负责监听分配给它的工作，同时运行若干个Worker进程

Storm使用Zookeeper作为分布式协调组件，负责Nimbus和多个Supervisor之间的协调，这样就算进程意外终止，重启也能读取、回复之前的状态。
![](https://i.postimg.cc/cCYJrQBc/11-16.png)

![](https://i.postimg.cc/GhqWv4gP/11-16-1.png)

Worker进程：
- Worker进程：每个worker进程属于一个特定的Topology，每个Supervior节点的worker可以有多个，每个worker对Topology中的每个组件（Spout或Bolt）运行一个或者多个executor线程来提供task的运行服务
- Executor：Executor是产生于worker进程内部的线程，执行同一组件的一个或多个task
- Task：实际的数据处理

![](https://i.postimg.cc/W4ng4P14/11-17.png)

### 10.5 Spark Streaming
![](https://i.postimg.cc/DyPX6T1P/11-19.png)

基本原理是将实时输入数据流以时间片（秒级）为单位进行拆分，然后经过Spark引擎以类似批处理方式处理每个时间片
![](https://i.postimg.cc/pdp5P54s/11-20.png)

Spark Streaming 最主要抽象是DStream（Discretized Stream，离散化数据流），表示连续不断的数据流。内部实现上是将输入数据按秒分成DStream，然后转换为RDD，最终变为RDD操作。
![](https://i.postimg.cc/htGf07DK/11-21.png)

## 10.5.2 Spark Streaming 与 Storm的对比
- 最大区别： Spark Streaming无法实现毫秒级流计算，而Storm可以实现毫秒级
- Spark Streaming构建在Spark上，一方面是因为Spark的低延迟执行引擎用于实时计算，另一方面，RDD数据集更容易做高效的容错处理
- Spark Streaming采用小批量处理，兼顾了批量和实时处理的逻辑和算法，方便历史数据和实时数据联合分析的特定场景

